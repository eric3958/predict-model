import pandas as pd
import numpy as np
import joblib
from sentence_transformers import SentenceTransformer

# 1. è¼‰å…¥è³‡æ–™
print("ğŸš€ è¼‰å…¥è³‡æ–™èˆ‡æ¨¡å‹...")
df = pd.read_csv("youtube_trending.csv")
df["collected_at"] = pd.to_datetime(df["collected_at"])
df = df[["video_id", "title", "views", "likes", "comments", "collected_at"]]
df = df.sort_values(by=["video_id", "collected_at"])

# 2. è¨ˆç®—æˆé•·ç‡
df["view_growth"] = df.groupby("video_id")["views"].pct_change().fillna(0)
df["like_growth"] = df.groupby("video_id")["likes"].pct_change().fillna(0)
df["comment_growth"] = df.groupby("video_id")["comments"].pct_change().fillna(0)

# 3. è¨ˆç®—æ¨è–¦åˆ†æ•¸
print("ğŸ“¡ è¨ˆç®—æ¨è–¦ç›¸ä¼¼åº¦...")
model = SentenceTransformer('all-MiniLM-L6-v2')
df["full_text"] = df["title"].fillna('')
df["recommend_score"] = df["full_text"].apply(
    lambda text: np.inner(model.encode(text), model.encode("æœ€æ–°ç§‘æŠ€ç”¢å“ã€3Cé–‹ç®±ã€TikTokçˆ†ç´…ã€Amazonå¥½ç‰©"))
)

# 4. æº–å‚™ç‰¹å¾µ
features = ["view_growth", "like_growth", "comment_growth", "recommend_score"]
X = df[features]

# 5. è¼‰å…¥æ¨¡å‹
clf = joblib.load("model.pkl")

# 6. é æ¸¬çˆ†ç´…æ©Ÿç‡èˆ‡æ¨™ç±¤
df["predict_is_viral"] = clf.predict(X)
df["predict_proba"] = clf.predict_proba(X)[:, 1]  # é æ¸¬æ©Ÿç‡ï¼ˆçˆ†ç´…çš„å¯èƒ½æ€§ï¼‰

# 7. ç¯©é¸é«˜æ©Ÿç‡å½±ç‰‡ï¼ˆå¯ä»¥è‡ªè¡Œèª¿æ•´é–€æª»ï¼‰
viral_predictions = df[df["predict_proba"] > 0.8].sort_values(by="predict_proba", ascending=False)

# 8. è¼¸å‡º
print("\nğŸ”¥ é æ¸¬æœ‰æ©Ÿæœƒçˆ†ç´…çš„å½±ç‰‡ï¼š\n")
print(viral_predictions[["title", "predict_proba", "view_growth", "collected_at"]])

viral_predictions.to_csv("predicted_viral_candidates.csv", index=False)
print("\nâœ… çµæœå·²å„²å­˜ç‚º predicted_viral_candidates.csv")
